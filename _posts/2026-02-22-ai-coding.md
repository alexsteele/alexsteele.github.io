---
layout: post
title:  "AI Coding Notes - Early 2026"
permalink: /:title/
date:   2026-02-22 00:00:00 -0800
---

Opinions on the state of AI coding tools after a year of daily LLM use and a
couple weekends trying Codex.

- They're quite good. If it's been done before, they can do it. And
  everything's been done before.
- Codex wrote a tensor library in C in about 30 minutes with some supervision,
  including a demo neural net and bigram LLM. With supervision and iteration,
  quality and style were similar to what I would do, but it's far faster.
- They still need human supervision. Left to their own devices, they
  occasionally make horrendous mistakes. They can get lost when they go
  off-track.
- They are absolutely outstanding research tools. Superhuman information
  retrieval and summary. If you are familiar with a field, you can summarize
  new concepts and mental models incredibly fast. Socratic-method-style Q&A
  really shines.
- They can do math semi-reliably with supervision. They couldn't 2 years ago.
  Chain-of-thought and improved training sets really helped.
- To enter the kingdom of vibes, you have to let go of your prior notions of
  quality. The AI does not code like you. It doesn't write like you. It's not
  smart in some ways, and it's truly superhuman in others. It is an alien
  machine babbler. It can still get things done under your direction.
- Productivity improvements seem in the 3-10x range for pure software
  implementation work, but it varies widely. Truly complicated and somewhat
  novel stuff is still best done by hand, but that's a small fraction of total
  work.
- They work best when you work methodically: planning first, coming up with test
  cases, then implementing. But they work surprisingly well in pure-vibe mode as
  well, where you leave them entirely to their own devices and spot- check the
  output. The code can still be repetitive and ugly, but they're usually able to
  improve it with some hints.
- All the frontier models are good: Gemini 3.1, GPT-5 Codex, Claude Opus. They
  all seem pretty solid. Gemini seems the smartest, but is not as good at
  writing code for some reason.
- I am fairly confident almost all IT professionals can benefit from using
  these models, starting with research-assistant-type tasks, then moving to
  semi-supervised smaller tasks like running SQL queries, writing code,
  analyzing spreadsheets, etc.
- I *am not at all confident* in letting swarms of agents loose, but it's cool
  that people are experimenting with this. I shudder at the absolute disaster
  babble messes and security disasters that will ensue.
